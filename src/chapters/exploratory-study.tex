% !TEX root = ../main.tex

\chapter{Exploratory study} % (fold)
\label{chp:exploratory_study}

The exploratory study is an important part of this research, since there already are lots of libraries that have been made to make search user interfaces with Algolia.

There's no point in proposing new ideas, and then figuring out that it was already tried, and dismissed for good reasons. To be able to both gather information about the existing solutions, but also find new solutions, this study is divided into two main points. The first point is discovery. In that section the methods in which the existing libraries are being used are explained, as well as the method used in this research to discover them. 

The second part is a run-down of all possible ways to make a search interface using JavaScript and Algolia. 

\section{Discovery}
\label{sec:discovery}

A way to discover all intricacies of an ecosystem is to use it in a lot of different ways. Before jumping into making a new \gls{library} or improving an existing one, one should use it sufficiently.

To do that, two main methods are used. Firstly it is to convert an existing search implementation using InstantSearch.js\cite{instantsearch-js} to use React InstantSearch in a more complex heavily used production website. For that purpose the website of the package manager Yarn\cite{yarn-site} was chosen.

The other method chosen for this goal is being a full member of the support experience at Algolia. Every developer takes care of their own libraries in all support channels, which helps a lot in finding out whether certain things are wanted by customers, or certain others aren't. This also helps in finding bugs and understanding weaknesses in the product.

\subsection{Yarn} % (fold)
\label{ssec:yarn}

Yarn is an open source package manager developed jointly by engineers at Facebook, Google and Tilde for the JavaScript ecosystem, based on the npm package manager. It allows for code to be easily shared among everyone in the world~\cite{yarn-site}~.

In both the npm and Yarn ecosystem code is shared in packages --- also called modules --- which all have a {\tt package.json} file that describes metadata on the package, together with all the code. Yarn and npm share the npm repository for having the packages of the ecosystem.

The Algolia team already worked on integrating Algolia search into the Yarn website~\cite{yarn-pr-add-algolia}~. Since the very beginning of 2017, itâ€™s possible to look up packages at a very impressive speed at \href{https://yarnpkg.com/search}{yarnpkg.com/search}. Making small fixes in the codebase\footnote{These fixes are the GitHub pull requests \href{https://github.com/yarnpkg/website/pulls/208}{yarnpkg/website\#208}, \href{https://github.com/yarnpkg/website/pulls/210}{yarnpkg/website\#210}, \href{https://github.com/yarnpkg/website/pulls211}{yarnpkg/website\#211} and \href{https://github.com/yarnpkg/website/pulls/335}{yarnpkg/website\#335} respectively} in the past made the project and research on further improving that search experience proved to be a very exciting endeavour.

The metadata in the npm and Yarn repository is being enriched by an indexing process\cite{npm-search} that takes in packages in the npm repository, and joins that together with places that have more information, like GitHub, and the amount of monthly downloads per package.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{../assets/yarn-search.png}
  \caption{Search results on the Yarn website in May 2017}
  \label{figure:yarn-search}
\end{figure}

This search experience was such a success that one week prior to the start of the internship in Paris, some of the team members (Sylvain Utard, Kevin Granger and Vincent Voyer) went to the Facebook offices in London --- Facebook has the main contributors to the Yarn project --- to explore the possibilities of making a detail page for the search, and integrating it even more into the website.

The Yarn project is evolving from having metadata from the npm packages in an index, used only on the Yarn website, to a free to use \acrshort{api}, which can make great search available to anyone who wants to make a project leveraging the ecosystem. The first other website that will use this data will be the online code editor \href{https://codesandbox.io}{CodeSandbox.io} for the interface where users can add dependencies to their projects. A lot of other integrations are expected in the time coming after this service will be formally announced.

% subsection yarn (end)
\subsection{Support}
\label{support}

At Algolia, customer support is not done by specific employees hired to do customer requests, but actually by the engineers and developers working on the code. This is a very varied list of people, who range from knowing a lot about a particular client or frontend \gls{library}, since they wrote it, to people working on the \gls{saas} client serving all requests.

This has as an effect that when someone starts in the company, after a few weeks, they get to interact with clients who use Algolia in very varied ways. Connecting to the users keeps the maintainers in an advantageous position, since it's very simple to find out what features to focus on, and bugs that weren't anticipated.

It also has a secondary effect, which is that it keeps everyone up to date with what is possible with a lot of different implementations.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{../assets/helpscout-integration.png}
  \caption{Company chat integration for the support interface}
  \label{figure:support}
\end{figure}

This is also a venue in which in a short time, deep knowledge about the \acrshort{api} parameters and the layers of abstraction is acquired. This has a similar influence on the understanding of libraries as using the libraries in a production website.

\section{Making search interfaces with Algolia} % (fold)
\label{sec:making_search_interfaces_with_algolia}

There have been several phases in the life of Algolia regarding building user interfaces on the web. In short, first there was only the \acrshort{rest} \acrshort{api} with the Algolia JavaScript client. Following to that, tutorials were written on how to use Algolia to build full search interfaces using technologies like jQuery, moment.js and other libraries. As a result keeping track of the search state is left over completely to the users to implement.

In the context of a search experience, the state of a page are the active refinements. This can often be seen in a specific widget, which is called {\tt currentRefinements} in the Algolia libraries. To make complex applications, the most important part is to have clean state handling, so that what the users see is always what they are interacting with.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{../assets/current-refinements.png}
  \caption{Current Refinements in React InstantSearch\cite{ris-storybooks}}
  \label{figure:current-refinements}
\end{figure}

To avoid having users to keep the state of their search experience by themselves, the Algolia JavaScript helper~\cite{algolia-js-helper} was written. Its goal is to be a reference to the state of the search, and provide ways to change the state.

When an abstraction for the search state has been made, it becomes a lot more straight-forward to make reason about what a certain action actually does. For example, it becomes trivial to make for example a button that changes the page of the search results.

However, when using the JavaScript Helper, there are still two major roadblocks that are left in \gls{userspace}. These roadblocks are linked to more advanced components, like for example a refinement list. A refinement list is a component that holds a list of possible filters which are relevant to the currently set refinements. It will also show how many results there would be, if that filter is chosen.

To make a component like a RefinementList, the struggle is one one side that a lot of different functions have to be called to be able to get the data, since behind the screens actually two \acrshort{api} queries happen. One to get the counts and one to get the results. The second hurdle that would need to be crossed is the actual rendering. A user would need to decide which markup structure to use, as well as the accessibility and usability implications of it.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.4\textwidth]{../assets/refinementlist.png}
  \caption{a RefinementList in React InstantSearch\cite{ris-storybooks}}
  \label{figure:refinementlist-ris}
\end{figure}

To solve both of these problems, in 2015 InstantSearch.js~\cite{instantsearch-js} was released by Algolia. It gives users of the \gls{library} a hook for every widget to mount it to their application, as well as leaving the possibility to change some of the markup structure by having a templating system built-in.

InstantSearch.js uses React behind the scenes. React\cite{react-doc} is a popular JavaScript \gls{library} for building user interfaces. One key thing of what React does is that it takes ownership of a part of a document structure. That -- ironically -- means that using InstantSearch.js in a React application is not a trivial operation.

Frameworks often impose a certain way of writing code that doesn't work well for libraries that are supposed to be used in a framework agnostic manner. For that reason, when making React InstantSearch~\cite{react-instantsearch} in 2016, the choice was made to not only expose components that mount to the \acrshort{dom}, but also expose another concept called connectors, which expose only the data that is relevant to a component, and a way to refine on it, relevant to that refinement.

This evolution makes for three distinct phases in how state has been handled, based on which \gls{library} is used.

What was noticed when creating React InstantSearch is that \emph{playing nice} with a framework makes the library a lot easier to use. Because of that realisation, one of the core goals of the coming period is to make InstantSearch available for other frameworks. Vue InstantSearch is the first of these new libraries, and will be released soon. It is inspired more by InstantSearch.js, but with the components as \acrshort{api} like in React InstantSearch. Other library integrations will probably start with Angular, Polymer and smaller libraries, but that will only be possible after some steps in reducing concerns in InstantSearch.js.

\subsection{Algolia JavaScript client} % (fold)
\label{sub:algolia_js_client}

When Algolia pivoted in 2013 to a \acrshort{saas} product~\cite{algolia-blog-saas}, \acrshort{api} clients~\cite{algolia-blog-lauch} for six programming languages were immediately available. JavaScript has always been important because of the focus on speed that Algolia has.

There are two major options to make a search experience. The first is to send a request from the frontend to the search service, where a \acrshort{json} response is returned, which then is uses to render results in client side code. The other is sending that same request via a form on an application-specific backend, and constructing the results there, and eventually sending a completely new page back as a result to the user's query.

Algolia has a preference for clients to construct the results on the frontend, mostly because it's a lot faster. Algolia has infrastructure~\cite{algolia-infra} all around the world, and thus having an extra roundtrip to wherever the backend of a client is, can take hundreds of milliseconds more. Since search seems slow as soon as the timeout takes more than 50ms, every millisecond matters.

The JavaScript client~\cite{algolia-js-client} is the lowest useful level of abstraction, and handles things like retry strategies, dropped requests, dynamic routing based on location and request fallbacks. Because it originally was the only way to query Algolia, it also supports setting individual parameters before searching.

When using just the JavaScript client, it can be noticed that all state should be handled inside the application code. That means keeping track whether a certain refinement has been set and unset, and keeping this consistent within the application code. Furthermore, the application needs to be aware when Algolia should be queried, and then handling all of the incoming results, dealing with out-of-order responses etc.

Making a user interface with just the JavaScript client requires you to take ownership of the search state. An intuitive to deal with the state then, is saving it as part as the \acrshort{dom}, for example by setting attributes.

This however isn't very efficient, since that implies that when the query needs to be changed somehow, there need to happen a lot of checks to see if the extra refinement is possible.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth]{../assets/js-client-state.pdf}
  \caption{Handling state with the JavaScript client}
  \label{figure:js-client-state}
\end{figure}

Adding a ``Clear All'' button in this structure is not trivial. There needs to be either a query for all elements that need to be updated, or they need to be kept up to date in a list. Then for each of those elements the relevant attributes would need to be updated or removed.

% subsection algolia_js_client (end)

\subsection{Algolia JavaScript Helper} % (fold)
\label{sub:algolia_js_helper}

Before being a separate concept, the ``Helper'' was an integral part of the JavaScript \acrshort{api} client~\cite{algolia-blog-js-client}~. In 2015 it was moved out as a standalone \gls{library} with as its main feature handling state of a search experience.

This means that when making a search experience, a new instance --- further called \emph{the} Helper for that view --- of the Helper is created. When it is being initialized, it creates a bond with a JavaScript \acrshort{api} client instance, to be used for sending the \acrshort{api} calls to the servers.

This Helper exposes functions to modify the current state. It has three kinds of those functions, which are:

\begin{enumerate}
  \item facets
  \item filters
  \item query parameters
\end{enumerate}

The Helper uses an observer pattern to be able to express listening to what happens in the search state, regardless of where it comes from. By attaching listeners to the instance, it's possible to react to every change that happens, and update the UI. This way there's only one central source of truth.

By providing a central place of truth for search state, a lot of the complexity in user land disappears immediately. When making a component that needs to change a facet, but it is only active when a different filter has been set, becomes simple, since all that needs to be used is a check on {\tt helper.getState()}, and if the condition is met, a {\tt helper.toggleFacetRefinement()} can be called.

Every time a new search request needs to be fetched, the {\tt results} observer is being triggered, and the search user interface can be updated with those new results.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth]{../assets/helper-cycle.pdf}
  \caption{Handling state with the JavaScript Helper\cite{js-helper-concepts}}
  \label{figure:js-helper-state}
\end{figure}

The functions of the Helper don't stop there, since more advanced use cases like ``Hierarchical faceting''\cite{hierarchical-faceting} are being handled. Hierarchical faceting is a concept, which requires the structure of the data to be formatted in a particular way to denote hierarchy. 

An example for hierarchical facets is given in figure \ref{figure:hierarchical-facets}. Here the {\tt hierarchicalCategory} \gls{attribute} will be used as a hierarchical facet. To be able to do that, it should be an Object, with {\tt lvlX} keys, where {\tt X} is the level of indentation. Inside each level the ``{\tt >}''-character is used as a level separator. That way an item could appear in multiple categories per level.

While hierarchical faceting is a core part of the search experience that users expect, it requires non-trivial knowledge of how to display these interfaces, and this thus seen as a ``niche'' feature. A need for higher level paradigms comes up in these situations.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth]{../assets/hierarchical-dashboard.png}
  \caption{Structure of a hierarchical facet in the Algolia dashboard}
  \label{figure:hierarchical-facets}
\end{figure}
% subsection algolia_js_Helper (end)

\subsection{InstantSearch.js} % (fold)
\label{sub:instantsearch_js}

InstantSearch.js was the solution to help people avoiding building the same solutions repeatedly. Its goal is to bridge the gap between the JavaScript Helper --- which has a very extensive \acrshort{api} --- and its users, who don't always have time to \gls{grok} all the options.

The chosen new method of building these user interfaces, is by wrapping the JavaScript Helper methods inside multiple widgets. This allows for a smaller API surface at the first point, and is easy to understand.

As a drawback of this structure, all of the internal representation of the widget rendering are being abstracted away. To be able to have a custom \acrshort{dom} structure, a solution had to be found. This solution is embedding the Hogan library to create \acrshort{dom}. As an effect, there is a mismatch between how the widgets work internally and its public \acrshort{api}.

To be able to allow making custom widgets, a custom widget can be made using InstantSearch.js. Making a custom widget requires knowledge of how the Algolia JavaScript Helper works, and its differences with the component model.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{../assets/is-js-state.pdf}
  \caption{Handling state with InstantSearch.js}
  \label{figure:is-js-state}
\end{figure}

\subsubsection{Connectors} % (fold)
\label{ssub:instantsearch_js_connectors}

To solve the mismatch between widgets that already exist and the need to define a complete custom rendering for it, connectors are proposed as a new \acrshort{api}. Connectors a concept first explored in React InstantSearch --- described in \ref{sub:react_instantearch} --- are connectors. In InstantSearch.js, connectors are added to version 2.0.0, which is at the time of writing available as a beta version.

Each of the widgets in InstantSearch.js are split up between its rendering, the component, and its Algolia logic, the connector. By doing this, the rendering of a widget is allowed to be chosen freely by the consumer of the \acrshort{api}. For example if another view model than \acrshort{dom} is needed in cases like NativeScript. 

Connectors in InstantSearch.js are implemented slightly different than in React InstantSearch in two main points. Firstly in InstantSearch.js more connectors are available than in React InstantSearch. The connectors that aren't available in React InstantSearch, but are in InstantSearch.js are connectors that existed as a separate widget in InstantSearch.js, and are actually derived connectors.

The second difference is architectural. In InstantSearch.js the connectors are available as a factory function, while in React InstantSearch this is a higher order component. A higher order component is a function which takes a React Component as argument and returns a new React Component, while a factory function will take a function as arguments and returns a function that can be used.

Providing these connectors is a first step in consolidating the rendering and logic between several InstantSearch libraries. Once a similar architecture is in place in both libraries, React InstantSearch could depend on the connectors of InstantSearch.js to make its higher order components internally, and components could be shared between both libraries.

To use a connector in InstantSearch.js, the parameters of the widget instance are being passed through to the \acrshort{dom} creation. A {\tt render} function will be called on each change in the InstantSearch state. To be able to create \acrshort{dom} containers on initial rendering, a second argument {\tt isFirstRendering} is in the signature of a connector. If that is {\tt true}, initial \acrshort{dom} creation can be implemented, while the contents of those nodes can update on every render.

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption={Initializing a searchbox connector in InstantSearch.js},label={lst:isjs-connector-searchbox}]
import instantsearch from 'instantsearch.js';

function render(
  {
    query,
    onHistoryChange,
    refine,
    widgetParams,
  },
  isFirstRendering,
) {
  const {node} = widgetParams;
  if (isFirstRendering) {
    node.placeholder = widgetParams.placeholder;
    node.addEventListener('input', e => refine(e.target.value));
  }
}

export default instantsearch.connectors.connectSearchBox(render);
\end{lstlisting}
\end{minipage}

Using this custom searchbox inside an InstantSearch instance is exactly the same as implementing the built-in widgets. This is because the same signature is being fulfilled by both implementations.

This pattern has been tested out with jQuery and JavaScript without any libraries for the documentation of InstantSearch.js, but also been experimented inside the etch rendering \gls{library} made for rendering inside the Atom code editor.

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption={Configure in an InstantSearch container},label={lst:isjs-connector-usage}]
import instantsearch from 'instantsearch.js';
import searchBox from './customSearchbox';

const search = instantsearch({
  appId: 'latency',
  apiKey: '6be0576ff61c053d5f9a3225e2a90f76',
  indexName: 'instant_search',
});

search.addWidget(
  searchBox({
    node: document.getElementById('search-box'),
    placeholder: 'Search for products',
  })
);

search.start();
\end{lstlisting}
\end{minipage}

% subsubsection instantsearch_js_connectors (end)

\subsubsection{Vue InstantSearch} % (fold)
\label{ssub:vue_instantsearch}

Vue InstantSearch is the newest version of InstantSearch, which takes a similar strategy to InstantSearch.js, but mixing in the power of the Vue \gls{library}, by exposing components, and not a ``proprietary'' format of widgets.

In contrast to InstantSearch.js, not the JavaScript Helper is being used to communicate with the Algolia \acrshort{rest} \acrshort{api}, but a new small layer on top of it. As described in more detail in section \ref{ssec:Subscribing}, Vue will take in account the {\tt getters} of an Object. These getters are written as a function, which will be called periodically by the Vue \gls{library}. 

To be able to take the current refinements in a performance aware way, the 

Vue InstantSearch is a project mostly done by Raymond Rutjes, but with me in all meetings about it, and with the complete thought process being done shared by both parties.

In the future, Vue InstantSearch will be the first \gls{library} to try the experimentation described in chapter \ref{chp:execution}, since it explicitly made it close to the \acrshort{api} of InstantSearch Core.

As an experiment with Lucas Bonomi, a way to use the connectors of InstantSearch.js with Moon --- a \gls{library} very close to Vue in it's \acrshort{api} --- has been made internally. This proves that connectors will be a way to make InstantSearch available to various other programming libraries in the future.

% subsubsection vue_instantsearch (end)


% subsection instantsearch_js (end)

\subsection{React InstantSearch} % (fold)
\label{sub:react_instantearch}

React InstantSearch doesn't directly use the JavaScript Helper, but it rather stores its component state in a separate container. This container is being managed by an {\tt InstantSearchManager}. It will take in the parameters to change at any given moment by the components, and transfer that into both a state to be used by the components, as well as sending requests.

Similar to the newer v2 version of InstantSearch.js, described in \ref{ssub:instantsearch_js_connectors}, React InstantSearch introduced the concept of connectors and components, that together make a widget.

A connector will define to the InstantSearch Manager what parameters are being tracked, and thus will be updated on every time new results come in. These connectors expose a {\tt refine} function, which depending on the exact widget will be called with a string, array, Object or number.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth]{../assets/is-react-state.pdf}
  \caption{Handling state with React InstantSearch}
  \label{figure:is-react-state}
\end{figure}

The connectors in React InstantSearch are implemented as higher order components, also called decorators. They will merge the \gls{props} that a component receives with the \gls{props} that will come from the Algolia implementation. This method of distributing data to children is also used by other popular React libraries like React Router and React Redux.

React InstantSearch doesn't stop at that place, it completely abstracts away the JavaScript Helper, and makes it impossible to actually use the Helper functions. This is done with a similar reason in how React abstracts away the \acrshort{dom}. When you'd change something in the JavaScript Helper, but not in the state tracking of React InstantSearch, it would cause confusion, and possibly collusions.

React InstantSearch proposes two different ways of countering this lack of visibility: the {\tt Configure} widget, and {\tt createConnector}.

\subsubsection{Configure}
\label{ssub:ris-configure}

The configure widget is a widget, which does not expose rendering, but rather only exists for the \gls{props} being set on it. Every prop that is set on a Configure widget is being passed down towards the used Algolia JavaScript client.

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption={Configure in an InstantSearch container},label={lst:ris-configure}]
const App = ({isDistinct, children}) => (
  <InstantSearch
    appId="latency"
    apiKey="6be0576ff61c053d5f9a3225e2a90f76"
    indexName="ikea"
  >
    <Configure distinct={isDistinct} />
    {children}
  </InstantSearch>
);
\end{lstlisting}
\end{minipage}

Here an app component is being made, which will take in as \gls{props} a boolean which decides whether to set the {\tt DISTINCT} parameter to true or false, and the children of that app.

React causes a new render every time something changes in the \gls{props}. Because of that behaviour, the mapping from the \gls{props} on Configure, together with the \gls{props} of other widgets can happen at render time.

\subsubsection{createConnector}
\label{ssub:ris-createconnector}

Every widget has its corresponding connector, as well as a few connectors that exist without default widget. A list of connectors that currently exist without default rendering implementation are {\tt connectAutoComplete} and {\tt connectRange}.

The AutoComplete and Range components only exist as a connector, because they imply significant style and \acrshort{dom} knowledge. Since there exist a few third-party implementations of these components that can be used with external data, it's fairly straightforward to use the connector Higher order Component as a way to pass through the data to the component, and call the {\tt refine()} function in click handlers. 

However providing a connector for every single possible widget would not be feasible. Therefore a factory function {\tt createConnector} exists.

To make a connector, the {\tt createConnector} function is being called with an Object as its argument. This can be seen as an abstract class, in which some to all of the default behaviour can be overridden. 

The most important key of that Object is the {\tt refine} function. This function will take in some parameters defined by the Component using the new custom connector, but also the current search state, as well as some other data about the current search~\cite{react-instantsearch-custom-connectors}~.

While this is not extremely hard, it's still a bridge to cross, since it requires users to \emph{really} understand how function composition works, and have to have a complete understanding of the architecture of React InstantSearch.

Although this sounds like it's hard to make very complicated and extended user interfaces using React InstantSearch, that is not exactly the case. Because the existing connectors cover most of the Algolia parameters that map to a user interface, these connectors allow for user interfaces that aren't necessarily predictable when designing the \acrshort{api}s. 

For example, it's perfectly possible to make a calendar input using a range connector, while the first use case was simply for numbers.

% subsection react_instantearch (end)

\subsection{The future} % (fold)
\label{sub:the_future}

In the future, if InstantSearch Core is chosen as the new abstraction level, there would not be a need to abstract away the JavaScript Helper. 

Since InstantSearch Core --- as described in section \ref{sec:organizing_state} --- maps the state of the each component to its \gls{attribute} name, a widget can be described both by its type and by its attribute. Refining a single attribute with multiple types of attributes is rarely --- if ever --- applicable, but it's common to have multiple identical types of refinement.

Each attribute contains an object with the type of refinement used, as well as a value. This value can be different datatypes, depending on the type of refinement. This structure makes it straightforward to render only the needed widgets and keep their data updated.

When using InstantSearch Core, the libraries using it would be able to expose it as a way to expand towards other connectors and widgets that aren't provided by default.

That way, the experience of creating other connectors will feel like a native feature, instead of a separate \gls{library} that a user would need to learn and understand first.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{../assets/is-core-state.pdf}
  \caption{Handling state with the InstantSearch Core}
  \label{figure:is-core-state}
\end{figure}

This structure, which is described in more detail in chapter \ref{chp:execution} extends the JavaScript Helper's functionality to be able express the notion of a \glspl{refinement} or a widget in the library itself. This library allows for a more modular approach towards state handling, since it transforms the \acrshort{api} responses based on which \glspl{refinement} are enabled, since the \glspl{refinement} itself provides how to transform its results to be usable. See also section \ref{sec:getting_responses_from_the_api} for details on that process.

% subsection the_future (end)

% section making_search_interfaces_with_algolia (end)
