% !TEX root = ../main.tex

\chapter{Technical development} % (fold)
\label{chp:execution}

\section{Terminology}
\label{sec:terminology}

To work with the Algolia \acrshort{api}, the first step is pushing by uploading schemaless \acrshort{json} Objects to an \gls{index}. The fact that the data is schemaless allows for a flexible data structure, because not every Object needs to have all types defined. For example clothing could have a ``colour'' attribute that does not make sense for a bar of chocolate.

Retrieving relevant results for a query in Algolia is done by a so-called tie-breaking algorithm. A user will set up what the order of importance for each rule is. For example, a name should be very important, but its order should be analysed not on alphabetical order, but on a list of criteria. While these criteria can be changed per \gls{index}, it's advised to keep the default ordering, which is:

\begin{enumerate}
  \item Typo
  \item Geo (if applicable)
  \item Words
  \item Proximity
  \item Attribute
  \item Exact
  \item Custom
\end{enumerate}

This means that the first results will be those without any typos, followed by those that are very close if location is relevant in that query. After that, if the query contains of multiple words, the results with the most matching words will come. If there are the same amount of words in two results, the one where those words are the closest together will come first --- for example ``George Clooney'' is more relevant than ``I like my neighbour George, he's nothing like Clooney''. The next criterion is which attribute the result is in. When deciding which attributes are searchable, a user will implicitly decide which order the attributes will be sorted in. For example, the name might be more relevant than the description. In that case, a user will put the {\tt name} attribute first in the searchable attributes. If the attribute in which the match happens is exactly the same, matches that match a whole word, versus just a prefix of a word will be considered more relevant~\cite{algolia-relevance}~.

Finally, custom relevance can be put into account when sorting. The custom ranking is an attribute that can be sorted ascending ord descending, and will contain business relevance. In the example of Yarn, the number of monthly downloads will decide as a last factor, which match will show up first. This allows for a algorithm which can be changed on the fly, by having multiple indices that replicate each other, but have different index settings.

Algolia uses this tie-breaking algorithm as one of its main features and differentiators from other searching engines like Lucene or ElasticSearch. Most, if not all, of its competitors use a \acrshort{tfidf} algorithm. \acrshort{tfidf} stands for ``\acrlong{tfidf}'', which works very well for big documents of text, for example a website or a pdf document. Algolia however is focused on database entries, which have the advantage of already being structured.

Executing a query is done via a \acrshort{rest} \acrshort{api}. While it's possible to send http requests, Algolia expects this to be done via the JavaScript client, which will set parameters for each filter. Most filters either take the value for a certain \gls{attribute}, or be a standalone filter. A library that is higher level than the JavaScript \acrshort{api} client should still allow to set each parameter without making it very complicated.

\input{chapters/execution/organizing-state}
\input{chapters/execution/handling-state-changes}

\section{Getting responses from the \acrshort{api}} % (fold)
\label{sec:getting_responses_from_the_api}

Until now, all state operations only applied to the local view, but no \acrshort{api} calls have been made. Since Algolia queries are called via its \acrshort{api}, it's very important that these \acrshort{api} calls will happen as soon as something in the query state changes. 

A subscription to the main state is made to make sure that every time the state

another function listens to changes in state %%

it transforms params into a JS client request

it replaces the {\tt response} in the state with an action

% section getting_responses_from_the_api (end)

\section{Rendering \glspl{refinement}} % (fold)
\label{sec:rendering_refinements}

When using InstantSearch to render refinement in a widget or a connector, it comes down to three distinct steps:

\begin{enumerate}
  \item create the refinement
  \item update the relevant \acrshort{dom} with the data from Algolia
  \item send \glspl{refinement} when certain events are triggered
\end{enumerate}

The things that need to happen here are almost exactly what needs to happen when making a connector using InstantSearch.js. React InstantSearch is more of an exception here, since it uses the functional composition of connector functions.

In regular JavaScript, these paradigms could go over the heads of normal developers, which is why the choice to leave the two definitions of connectors.

\subsection{Creating a refinement}
\label{subs:creating_a_refinement}

To create a refinement, two steps happen. Firstly a new refinement container is created. This has a very similar structure as described in section \ref{ssec:refinments}. The next step is to register that refinement to the InstantSearch store.

As an example, a refinement list is created from the ``brands'' attribute. %%

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption={Creating a refinement},label={lst:creating-refinement}]
import { createRefinementlist } from 'instantsearch-core/refinements';

const brands = createRange({attributeName: 'brands'});

export default brands;
\end{lstlisting}
\end{minipage}

blimbo: do it cool and register %%

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption={Registering a refinement},label={lst:registering-refinement}]
import { store } 
\end{lstlisting}
\end{minipage}

\subsection{Updating or creating \acrshort{dom} with Algolia data}
\label{subs:data_to_dom}

Simple dom making yo %%

\subsection{Calling the {\tt refine} function}
\label{subs:refining}

yo press the button and update the dom %%

% section rendering_\glspl{refinement} (end)

\section{Saved state} % (fold)
\label{sec:saved_state}

The \acrshort{api} also allows for an initialisation with a certain state passed in. This means that it's possible to save a state Object in a location, and then later restart the search from that data. 

This is useful for three major use cases. The first is \acrshort{url} synchronisation. For \acrshort{url} synchronisation the structure would be to first listen on every state change with {\tt .subscribe()}, and then asynchronously transform that to query parameters to set. If a user comes to a page with query parameters, a function to take in the query string and put out a state Object would then be called. After that point a new InstantSearch Core instance can be built with the {\tt preloadedState} parameter set in the constructor.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth, height=0.2\textheight, draft]{../assets/is-core-url-sync.pdf}
  \caption{Synchronisation with the querystring using InstantSearch Core}
  \label{figure:is-core-url-sync}
\end{figure} %%

Similarly it is also possible to do that process with a different medium than query parameters, for example {\tt localStorage}. For that reason this process is left over to the user, possibly with other small packages dealing with browser inconsistencies on top of it. 

This pattern is also useful for when \acrfull{ssr} is implemented. When ...%%

\begin{enumerate}
  \item execute the IS function once
  \item render the output as html
  \item also output the state Object in a global Object
  \item send that html to the client
  \item start the IS instance frontend with preloadedState: {\tt window.PRELOADED\_STATE} %%
\end{enumerate}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth, height=0.2\textheight, draft]{../assets/is-core-ssr.pdf}
  \caption{Server Side Rendering with InstantSearch Core}
  \label{figure:is-core-ssr}
\end{figure} %%

% section saved_state (end)

\section{Overview} % (fold)
\label{sec:overview}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{../assets/architecture.pdf}
  \caption{Architecture overview\cite{blog-architecture}}
  \label{figure:core-architecture}
\end{figure}

TODO: update this image with more recent architecture %%

% section overview (end)

\section{Usage in libraries} % (fold)
\label{sec:usage_in_libraries}

PoC in instantsearch.js and React InstantSearch for the RefinementList %%

% section usage_in_libraries (end)
